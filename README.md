# nlp-reliability-analysis
This project explores the use of Transformer-based NLP models (like BERT, RoBERTa, and XLNet) to classify textual data based on reliability and source authenticity.

### Tasks Covered:
- **Spam Detection** – Classifying online reviews as spam or not.
- **Fake News Identification** – Detecting misleading or false news articles.
- **AI-Generated Text Detection** – Identifying whether text is written by a human or an AI model.

### Models Used:
- BERT
- DistilBERT
- ALBERT
- RoBERTa
- XLNet

### Dataset:
Balanced datasets from Kaggle (12,000 samples per task).

### Results:
RoBERTa achieved the highest overall performance, while XLNet performed best on AI detection.

### Highlights:
- Emotion-aware fine-tuning analysis
- Comparative performance evaluation
- Preprocessing, tokenization, and custom classification head

